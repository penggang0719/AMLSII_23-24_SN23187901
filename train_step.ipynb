{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Import necessary functions and classes from the 'A'\n",
    "from A.srcnn_data import preprocess_image, srcnn_image_generator, display_comparison, compare_single_images\n",
    "from A.srcnn import create_srcnn_model, psnr, predict_images, compare_average_psnr\n",
    "\n",
    "# Import necessary functions and classes from the 'B'\n",
    "from B.espcn_data import espcn_image_generator\n",
    "from B.espcn import create_espcn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the physical GPUs available\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "# This allows TensorFlow to automatically use as much GPU memory as needed and only when required.\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directories where the training and validation images are stored\n",
    "train_hr_dir = 'Datasets/DIV2K_train_HR' \n",
    "train_lr_bicubic_dir = 'Datasets/DIV2K_train_LR_bicubic_X4'\n",
    "train_lr_unknown_dir = 'Datasets/DIV2K_train_LR_unknown_X4'\n",
    "valid_hr_dir = 'Datasets/DIV2K_valid_HR'\n",
    "valid_lr_bicubic_dir = 'Datasets/DIV2K_valid_LR_bicubic_X4'\n",
    "valid_lr_unknown_dir = 'Datasets/DIV2K_valid_LR_unknown_X4'\n",
    "\n",
    "# Preprocess the validation images\n",
    "valid_hr_ds = preprocess_image(valid_hr_dir, 600)\n",
    "valid_lr_bicubic_ds = preprocess_image(valid_lr_bicubic_dir, 150)\n",
    "valid_lr_unknown_ds = preprocess_image(valid_lr_unknown_dir, 150)\n",
    "\n",
    "# Resize the low resolution validation images to the same size as the high resolution images\n",
    "valid_lr_bicubic_ds_resized = np.array([cv2.resize(img, (600, 600), interpolation=cv2.INTER_CUBIC) for img in valid_lr_bicubic_ds])\n",
    "valid_lr_unknown_ds_resized = np.array([cv2.resize(img, (600, 600), interpolation=cv2.INTER_CUBIC) for img in valid_lr_unknown_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target size and batch size for the image generators\n",
    "low_res_target_size = 150\n",
    "high_res_target_size = 600\n",
    "generator_batch_size = 2\n",
    "\n",
    "# Create training image generators for the SRCNN model\n",
    "srcnn_bicubic_gen = srcnn_image_generator(train_lr_bicubic_dir, train_hr_dir, low_res_target_size, high_res_target_size, generator_batch_size)\n",
    "srcnn_unknown_gen = srcnn_image_generator(train_lr_unknown_dir, train_hr_dir, low_res_target_size, high_res_target_size, generator_batch_size)\n",
    "\n",
    "# Create training image generators for the ESPCN model\n",
    "espcn_bicubic_gen = espcn_image_generator(train_lr_bicubic_dir, train_hr_dir, low_res_target_size, high_res_target_size, generator_batch_size)\n",
    "espcn_unknown_gen = espcn_image_generator(train_lr_unknown_dir, train_hr_dir, low_res_target_size, high_res_target_size, generator_batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track 1: Bicubic x4 SRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SRCNN model for the bicubic downsampled images. This process may take around 7.5 hours.\n",
    "# bicubic_srcnn_model = create_srcnn_model()\n",
    "# bicubic_srcnn_model.summary()\n",
    "# bicubic_srcnn_model.fit(bicubic_gen, steps_per_epoch=2000, epochs=50)\n",
    "# bicubic_srcnn_model.save('A/bicubic_srcnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previously trained SRCNN model and use the loaded model to predict the high resolution images\n",
    "bicubic_srcnn_model = load_model('A/bicubic_srcnn_model.h5', custom_objects={'psnr': psnr})\n",
    "\n",
    "# Define the batch size for the prediction \n",
    "prediction_batch_size = 10 \n",
    "srcnn_bicubic_pred_images = predict_images(bicubic_srcnn_model, valid_lr_bicubic_ds_resized, prediction_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track 1: Bicubic x4 ESPCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ESPCN model for the bicubic downsampled images. This process may take around 5 hours.\n",
    "# bicubic_espcn_model = create_espcn_model()\n",
    "# bicubic_espcn_model.summary()\n",
    "# bicubic_espcn_model.fit(espcn_bicubic_gen, steps_per_epoch=2000, epochs=50)\n",
    "# bicubic_espcn_model.save('A/bicubic_espcn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previously trained ESPCN model and use the loaded model to predict the high resolution images\n",
    "bicubic_espcn_model = load_model('A/bicubic_espcn_model.h5', custom_objects={'psnr': psnr})\n",
    "espcn_bicubic_pred_images = predict_images(bicubic_espcn_model, valid_lr_bicubic_ds, prediction_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track 2: Unknown x4 SRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the SRCNN model for the unknown downsampled images. This process may take around 7.5 hours.\n",
    "# unknown_srcnn_model = create_srcnn_model()\n",
    "# unknown_srcnn_model.summary()\n",
    "# unknown_srcnn_model.fit(srcnn_unknown_gen, steps_per_epoch=2000, epochs=50)\n",
    "# unknown_srcnn_model.save('B/unknown_srcnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previously trained SRCNN model and use the loaded model to predict the high resolution images\n",
    "unknown_srcnn_model = load_model('B/unknown_srcnn_model.h5', custom_objects={'psnr': psnr})\n",
    "srcnn_unknown_pred_images = predict_images(unknown_srcnn_model, valid_lr_unknown_ds_resized, prediction_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Track 2: Unknown x4 ESPCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ESPCN model for the unknown downsampled images. This process may take around 5 hours.\n",
    "# unknown_espcn_model = create_espcn_model()\n",
    "# unknown_espcn_model.summary()\n",
    "# unknown_espcn_model.fit(espcn_unknown_gen, steps_per_epoch=2000, epochs=50)\n",
    "# unknown_espcn_model.save('B/unknown_espcn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previously trained ESPCN model and use the loaded model to predict the high resolution images\n",
    "unknown_espcn_model = load_model('B/unknown_espcn_model.h5', custom_objects={'psnr': psnr})\n",
    "espcn_unknown_pred_images = predict_images(unknown_espcn_model, valid_lr_unknown_ds, prediction_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the average PSNR of the original high resolution images, the SRCNN and ESPCN predicted high resolution images, and the bicubic low resolution images\n",
    "bicubic_lr_psnr, bicubic_srcnn_psnr = compare_average_psnr(valid_hr_ds, srcnn_bicubic_pred_images, valid_lr_bicubic_ds_resized)\n",
    "bicubic_lr_psnr, bicubic_espcn_psnr = compare_average_psnr(valid_hr_ds, espcn_bicubic_pred_images, valid_lr_bicubic_ds_resized)\n",
    "unknown_lr_psnr, unknown_srcnn_psnr = compare_average_psnr(valid_hr_ds, srcnn_unknown_pred_images, valid_lr_unknown_ds_resized)\n",
    "unknown_lr_psnr, unknown_espcn_psnr = compare_average_psnr(valid_hr_ds, espcn_unknown_pred_images, valid_lr_unknown_ds_resized)\n",
    "\n",
    "# Print the average PSNR values for the original and predicted images\n",
    "print(f'Original_bicubic_lr_Average PSNR: {bicubic_lr_psnr}dB')\n",
    "print(f'SRCNN_bicubic_Average PSNR: {bicubic_srcnn_psnr}dB')\n",
    "print(f'ESPCN_bicubic_Average PSNR: {bicubic_espcn_psnr}dB')\n",
    "\n",
    "print(f'Original_unknown_lr_Average PSNR: {unknown_lr_psnr}dB')\n",
    "print(f'SRCNN_unknown_Average PSNR: {unknown_srcnn_psnr}dB')\n",
    "print(f'ESPCN_unknown_Average PSNR: {unknown_espcn_psnr}dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 3 indices from the predicted high resolution images\n",
    "indices = np.random.choice(len(srcnn_bicubic_pred_images), 3, replace=False)\n",
    "\n",
    "# Use the selected indices to get the corresponding images from the different datasets\n",
    "selected_hr_images = valid_hr_ds[indices]\n",
    "selected_bicubic_lr_images = valid_lr_bicubic_ds_resized[indices]\n",
    "selected_unknown_lr_images = valid_lr_unknown_ds_resized[indices]\n",
    "\n",
    "selected_bicubic_srcnn_predicted_images = srcnn_bicubic_pred_images[indices]\n",
    "selected_bicubic_espcn_predicted_images = espcn_bicubic_pred_images[indices]\n",
    "selected_unknown_srcnn_predicted_images = srcnn_unknown_pred_images[indices]\n",
    "selected_unknown_espcn_predicted_images = espcn_unknown_pred_images[indices]\n",
    "\n",
    "# Display a comparison of the low resolution images, the predicted high resolution images, and the true high resolution images\n",
    "display_comparison(selected_bicubic_lr_images, selected_bicubic_srcnn_predicted_images, selected_hr_images, 'bicubic_srcnn_random_comparison')\n",
    "display_comparison(selected_bicubic_lr_images, selected_bicubic_espcn_predicted_images, selected_hr_images, 'bicubic_espcn_random_comparison')\n",
    "display_comparison(selected_unknown_lr_images, selected_unknown_srcnn_predicted_images, selected_hr_images, 'unknown_srcnn_random_comparison')\n",
    "display_comparison(selected_unknown_lr_images, selected_unknown_espcn_predicted_images, selected_hr_images, 'unknown_espcn_random_comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_single_images(selected_bicubic_lr_images[0], selected_bicubic_srcnn_predicted_images[0], selected_bicubic_espcn_predicted_images[0], selected_hr_images[0], 'compare_bicubic_single_images')\n",
    "compare_single_images(selected_unknown_lr_images[0], selected_unknown_srcnn_predicted_images[0], selected_unknown_espcn_predicted_images[0], selected_hr_images[0], 'compare_unknown_single_images')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AMLS2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
